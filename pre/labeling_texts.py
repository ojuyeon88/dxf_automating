# === labeling_texts.py (ìˆ˜ì • ì™„ë£Œ) ===
import ezdxf
import re
import csv
import os
from shapely.geometry import Polygon, Point
from collections import defaultdict

# ì„¤ì •
dxf_folder = "files/dxf"
output_csv = "pre/data/text_category_all.csv"
os.makedirs(os.path.dirname(output_csv), exist_ok=True)

# í‚¤ì›Œë“œ
KEYWORDS = ['í˜¸', 'ì‹¤', 'ê°•ì˜ì‹¤', 'ê³„ë‹¨', 'í™”ì¥ì‹¤', 'ì„¸ë¯¸ë‚˜', 'íšŒì˜', 'íœ´ê²Œ', 'ì—˜ë¦¬ë² ì´í„°', 'ì „ê¸°', 'ê¸°ê³„']
CATEGORY_KEYWORDS = {
    "lecture": ["ê°•ì˜ì‹¤", "ê³„ë‹¨ê°•ì˜ì‹¤"],
    "restroom": ["í™”ì¥ì‹¤", "ë‚¨ìí™”ì¥ì‹¤", "ì—¬ìí™”ì¥ì‹¤", "ì¥ì• ì¸í™”ì¥ì‹¤"],
    "stair": ["ê³„ë‹¨ì‹¤", "ê³„ë‹¨"],
    "elevator": ["ELEV", "ELEVì‹¤", "ì—˜ë¦¬ë² ì´í„°"],
    "ps": ["PSì‹¤", "ì „ê¸°", "ê¸°ê³„ì‹¤", "ê¸°ê³„"],
    "office": ["êµìˆ˜ì—°êµ¬ì‹¤", "ë¶€ì›ì¥ì‹¤", "í–‰ì •ì‹¤", "ë¶€ì†ì‹¤"],
    "seminar": ["ì„¸ë¯¸ë‚˜ì‹¤", "íšŒì˜ì‹¤", "ì„¸ë¯¸ë‚˜", "íšŒì˜"],
    "lab": ["ì—°êµ¬ì‹¤", "ì‹¤í—˜ì‹¤", "ì‹¤ìŠµì‹¤", "Testbed", "ì‹œìŠ¤í…œ", "CAD", "ë¡œë´‡", "ë¶„ì„ì‹¤"],
    "lounge": ["íœ´ê²Œì‹¤", "ìˆ™ì§ì‹¤", "ë…ì„œì‹¤", "íœ´ê²Œ"],
    "misc": []
}

def is_meaningful(text):
    text = text.strip()
    if len(text) < 2: return False
    if re.fullmatch(r'[\W_]+', text): return False
    if re.fullmatch(r'\d{3,5}', text): return False
    if any(kw in text for kw in KEYWORDS): return True
    if re.search(r'\d+[ê°€-í£]+', text): return True
    return False

def clean_text(text):
    text = re.sub(r"\d+(\.\d+)?ã¡", "", text)
    text = re.sub(r"[A-Z]*\d{2,4}(-\d+)?í˜¸ì‹¤?", "", text)
    IGNORE_KEYWORDS = ["ë„ë©´", "í‰ë©´ë„", "ì°½ì˜ê´€", "ì§€í•˜", "ì „ìš©ë©´ì ", "ã¡"]
    for kw in IGNORE_KEYWORDS:
        if kw in text:
            return ""
    return text.strip()

def categorize(text):
    for category, keywords in CATEGORY_KEYWORDS.items():
        if any(kw in text for kw in keywords):
            return category
    return "misc"

def normalize_floor(floor_str):
    floor_str = floor_str.upper().replace("F", "")
    if floor_str.startswith("B"):
        return -int(floor_str.replace("B", ""))
    return int(floor_str)

raw_results = []

for filename in os.listdir(dxf_folder):
    if filename.lower().endswith(".dxf"):
        filepath = os.path.join(dxf_folder, filename)
        print(f"[ğŸ“‚] ì²˜ë¦¬ ì¤‘: {filename}")
        try:
            doc = ezdxf.readfile(filepath)
            msp = doc.modelspace()
            floor = filename.split("-")[0]

            polygon_centers = []
            for entity in msp.query("LWPOLYLINE POLYLINE"):
                try:
                    if entity.dxftype() == "LWPOLYLINE":
                        points = [(p[0], p[1]) for p in entity]
                    else:
                        points = [(v.dxf.location.x, v.dxf.location.y) for v in entity.vertices()]
                    if len(points) < 3:
                        continue
                    polygon = Polygon(points)
                    if polygon.is_valid and polygon.area > 1000:
                        center = polygon.centroid
                        polygon_centers.append(center)
                except Exception as e:
                    print(f"  â”” í´ë¦¬ë¼ì¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

            for entity in msp.query("TEXT MTEXT"):
                try:
                    if entity.dxftype() == "TEXT":
                        content = entity.dxf.text
                        insert = entity.dxf.insert
                    elif entity.dxftype() == "MTEXT":
                        content = entity.plain_text()
                        insert = entity.dxf.insert
                    else:
                        continue

                    content = content.strip()
                    cleaned = clean_text(content)
                    if not cleaned or not is_meaningful(cleaned):
                        continue

                    category = categorize(cleaned)
                    tx, ty = insert.x, insert.y
                    text_point = Point(tx, ty)

                    min_dist = float('inf')
                    nearest_cx, nearest_cy = None, None
                    for center in polygon_centers:
                        dist = text_point.distance(center)
                        if dist < min_dist:
                            min_dist = dist
                            nearest_cx, nearest_cy = center.x, center.y

                    if min_dist < 5000:
                        raw_results.append((filename, floor, cleaned, category, round(nearest_cx, 2), round(nearest_cy, 2)))

                except Exception as e:
                    print(f"  â”” í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        except Exception as e:
            print(f"[âŒ] {filename} ì½ê¸° ì‹¤íŒ¨: {e}")

# ë³‘í•© ë¡œì§ (ì¢Œí‘œ ë°˜ì˜¬ë¦¼ ê¸°ë°˜)
clusters = defaultdict(list)
for row in raw_results:
    key = (row[0], normalize_floor(row[1]), row[3], round(row[4], -1), round(row[5], -1))
    clusters[key].append(row[2])

all_results = []
for (filename, floor, category, cx, cy), texts in clusters.items():
    merged_text = " ".join(sorted(set(texts)))
    all_results.append((filename, floor, merged_text, category, cx, cy))

print(f"[âœ”] ì´ {len(all_results)}ê±´ ì €ì¥ ì˜ˆì •")

with open(output_csv, "w", newline="", encoding="utf-8-sig") as f:
    writer = csv.writer(f)
    writer.writerow(["filename", "floor", "text", "category", "center_x", "center_y"])
    writer.writerows(all_results)

print(f"\n[âœ”] ì „ì²´ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_csv}")